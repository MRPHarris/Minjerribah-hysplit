---
title: "Minjerribah and K'gari rainfall"
author: Matt Harris
output: word_document
---

This Rmd file is optimised for figures output as separate tiff files. The figs in this doc may have odd scaling as a result.

```{r setup-main, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE, fig.show = 'hide'}
## SETUP CHUNK

## Get pacman for pacman::p_load() 
library(pacman)

## Load core packages. 
p_load(splitr, openair, lubridate, magrittr, tibble, 
       dplyr, R.utils, ggplot2, stringr, here, tidyverse, cowplot, ggh4x,forecast,
       RColorBrewer, ggtext)

# Updated mapping package list
p_load(maps, raster, mapdata, geosphere)

## Set directories
## All paths are specified relative to the proj_dir.
proj_dir = paste0(here(),"/")
setwd(proj_dir)
tiff_dir <- paste0(proj_dir,"figure TIFFs/")

## Functions 
# Source fn file
source(file = paste0(proj_dir,"scripts/functions.R"), echo = FALSE)

## Site latitudes and longitudes
# Sandy Cape, K'gari (Fraser Island)
SC_lat <- -24.73
SC_lon <- 153.21
# Point Lookout, Minjerribah (North Stradbroke Island)
PL_lat <- -27.44
PL_lon <- 153.55

## Non-mapping themes
source(file = paste0(proj_dir,"themes/Plotting_themes.R"), echo = F)

## Nino 3.4 from NOAA. Anomalies, monthly.
Nino3.4 = read.table(file = paste0(proj_dir,"data/NOAA-NINO3p4-Anom.txt")) %>%
  mutate(across(everything(), ~ as.numeric(.))) %>%
  mutate(across(everything(), ~na_if(.,-99.99))) %>%
  # column_to_rownames("V1") %>%
  'colnames<-'(c('Year',seq(1,12,1))) %>% 
  pivot_longer(cols = c(2:13), names_to = c("Month"), values_to = "Nino3.4") %>%
  mutate(across(everything(), ~ as.numeric(.))) %>%
  mutate(Month_seq = cumsum(c(0, as.numeric(diff(Month)) != 0)) + 1)
## Annualise
Nino3.4_ann <- Nino3.4 %>%
  group_by(Year) %>%
  summarise(avg = mean(Nino3.4)) %>%
  filter(Year > 1949)

## Get trajectory data
## Directory for data too big for github
## NB: the need for these datasets to produce the figures/clusters has been removed, as the data parsing to narrow down to 100mm events is now done in the 'cluster-calcs' code block. Happy to supply these as a onedrive/googledrive link if needed. 
external_data_dir = "C:/Users/mharris/work/projects/3 active/Minjerribah Tibby/data_ext/"
SC_72hr1TPD2000m_Reanalysis <- read.csv(file = paste0(external_data_dir,"SC_72hr1TPD2000m_Reanalysis_1950_2022.csv")) 
PL_72hr1TPD2000m_Reanalysis <- read.csv(file = paste0(external_data_dir,"PL_72hr1TPD2000m_Reanalysis_1950_2022.csv"))

```

```{r setup-mapping, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE, fig.show = 'hide'}
## SETUP CHUNK

## World data
world <- map_data("worldHires")

## 'Full' Basemap. Medium Zoom.
min_lon = 110 #left bounds
max_lon = 190 #right bounds
min_lat = -60 #lower bounds
max_lat = 10 # upper bounds
EastAus_Data <- world %>% 
  filter (lat > min_lat) %>%
  filter (lat < max_lat) %>%
  filter (long > min_lon) %>%
  filter (long < max_lon) %>%
  fortify()
rect_data_eastaus <- matrix(c(min_lon,max_lon,min_lat,max_lat))
EastAus_Full_Basemap <- list(
  geom_rect(aes(xmin = rect_data_eastaus[1]+5, xmax = rect_data_eastaus[2]-5, ymin = rect_data_eastaus[3]+5,ymax = rect_data_eastaus[4]-5), 
            fill = "white", alpha = 0.7),
  geom_map(data = EastAus_Data, map = EastAus_Data,
           aes(
             # x = long, y = lat, 
             group = group, map_id = region),
           fill = "#d9d9d9", colour = "#7f7f7f", size = 0.25),
  coord_map("rectangular", lat0 = 0, xlim = c(min_lon+5,max_lon-5), ylim = c(min_lat+5, max_lat-5)),
  scale_x_continuous(
    expand = c(0,0), limits = c(min_lon+5,max_lon-5), breaks = seq(min_lon+5,max_lon-5, 25)),
  scale_y_continuous(
    expand = c(0,0), limits = c(min_lat+5, max_lat-5), breaks = seq(min_lat+5, max_lat-5, 10)),
  theme_bw(),
  theme(
    panel.grid = element_line(size = 0.1, colour = "grey15", linetype = "dashed")),
  labs(title="", x="", y="")
)

## 'Zoomin' Basemap. Closer in. 
min_lon = 140 #left bounds
max_lon = 170 #right bounds
min_lat = -40 #lower bounds
max_lat = -10 # upper bounds
EastAus_Zoomin_Data <- world %>% 
  filter (lat > min_lat) %>%
  filter (lat < max_lat) %>%
  filter (long > min_lon) %>%
  filter (long < max_lon) %>%
  fortify()
rect_data_eastaus_zoomin <- matrix(c(min_lon,max_lon,min_lat,max_lat))
EastAus_Zoomin_Basemap <- list(
  geom_rect(aes(xmin = rect_data_eastaus_zoomin[1]+5, 
                xmax = rect_data_eastaus_zoomin[2]-5, 
                ymin = rect_data_eastaus_zoomin[3]+5,
                ymax = rect_data_eastaus_zoomin[4]-5), 
            fill = "white", alpha = 0.7),
  geom_map(data = EastAus_Zoomin_Data, map = EastAus_Zoomin_Data,
           aes(
             # x = long, y = lat, 
             group = group, map_id = region),
           fill = "#d9d9d9", colour = "#7f7f7f", size = 0.5),
  coord_map("rectangular", lat0 = 0, xlim = c(min_lon+5,max_lon-5), ylim = c(min_lat+5, max_lat-5)),
  scale_x_continuous(
    expand = c(0,0), limits = c(min_lon+5,max_lon-5), breaks = seq(min_lon+5,max_lon-5, 25)),
  scale_y_continuous(
    expand = c(0,0), limits = c(min_lat+5, max_lat-5), breaks = seq(min_lat+5, max_lat-5, 10)),
  theme_bw(),
  theme(
    panel.grid = element_line(size = 0.1, colour = "grey15", linetype = "dashed")),
  labs(title="", x="", y="")
)

## 'Zoomout' Basemap. Zoomed further out. More distorted.
min_lon = 80 #left bounds
max_lon = 190 #right bounds
min_lat = -65 #lower bounds
max_lat = 10 # upper bounds
EastAus_Zoomout_Data <- world %>% 
  filter (lat > min_lat) %>%
  filter (lat < max_lat) %>%
  filter (long > min_lon) %>%
  filter (long < max_lon) %>%
  fortify()
rect_data_eastaus_zoomout <- matrix(c(min_lon,max_lon,min_lat,max_lat))
EastAus_Zoomout_Basemap <- list(
  geom_rect(aes(xmin = rect_data_eastaus_zoomout[1]+5, 
                xmax = rect_data_eastaus_zoomout[2]-5, 
                ymin = rect_data_eastaus_zoomout[3]+5,
                ymax = rect_data_eastaus_zoomout[4]-5), 
            fill = "white", alpha = 0.7),
            # fill = "steelblue", alpha = 0.7),
  geom_map(data = EastAus_Zoomout_Data, map = EastAus_Zoomout_Data,
           aes(
             # x = long, y = lat, 
             group = group, map_id = region),
           fill = "#d9d9d9", colour = "#7f7f7f", size = 0.5),
  coord_map("rectangular", lat0 = 0, xlim = c(min_lon+5,max_lon-5), ylim = c(min_lat+5, max_lat-5)),
  scale_x_continuous(
    expand = c(0,0), limits = c(min_lon+5,max_lon-5), breaks = seq(min_lon+5,max_lon-5, 25)),
  scale_y_continuous(
    expand = c(0,0), limits = c(min_lat+5, max_lat-5), breaks = seq(min_lat+5, max_lat-5, 10)),
  theme_bw(),
  theme(
    panel.grid = element_line(size = 0.1, colour = "grey15", linetype = "dashed")),
  labs(title="", x="", y="")
)
#ggplot() + 
#  EastAus_Zoomout_Basemap

## SC_Point
SC_point_df <- as.data.frame(matrix(NA,1,2))
SC_point_df[,1] <- SC_lat
SC_point_df[,2] <- SC_lon
colnames(SC_point_df) <- c("lat","lon")
SC_point <- list(
  geom_point(data = SC_point_df, aes(x = lon, y = lat), shape = 21, fill = "white", size = 3)
)

## PL_Point
PL_point_df <- as.data.frame(matrix(NA,1,2))
PL_point_df[,1] <- PL_lat
PL_point_df[,2] <- PL_lon
colnames(PL_point_df) <- c("lat","lon")
PL_point <- list(
  geom_point(data = PL_point_df, aes(x = lon, y = lat), shape = 21, fill = "white", size = 3)
)

## Themes
generate_plot_themes <- function(axis_textsize = 6){
    plot_themes_monthfill <- list(
    theme(
      plot.title = element_text(size =  axis_textsize*9/6),
      legend.title = element_text(size =  axis_textsize*7/6),
      legend.text = element_text(size = axis_textsize*7/6),
      axis.text = element_text(size = axis_textsize)
    ),
    guides(
      fill=guide_legend(title="Month#"))
  )
  plot_themes_monthfill
}

plot_themes_monthfill <- list(
  theme(
    plot.title = element_text(size =  9),
    legend.title = element_text(size =  7),
    legend.text = element_text(size = 7),
    axis.text = element_text(size = 6)
    ),
    guides(
      fill=guide_legend(title="Month#"))
)

## Test map to confirm all the above is working
# ggplot() + 
#   EastAus_Zoomout_Basemap +
#   geom_map(data = EastAus_Zoomout_Data, map = EastAus_Zoomout_Data,
#            aes(
#              # x = long, y = lat, 
#              group = group, map_id = region),
#            fill = "transparent", colour = "grey8", size = 0.2) +
#   PL_point +
#   SC_point +
#   plot_themes_monthfill

```

Kgari ENSO work

"Is there a different spatial origin of precipitation to K'gari and/or Minjerribah during ENSO phases?" 

A contiguous suite of HYSPLIT atmospheric trajectory model runs were used to trace the atmospheric pathways of precipitation to K'gari and Minjerribah. Trajectories from each location were run backwards, daily, for 1950 - 2022. Release height of 2000 m, duration 72 hr, using NCEP/NCAR 2.5-degree reanalysis data.

Rainall records from Sandy Cape and Point Lookout were used to filter the trajectories to those arriving at the sites on days where >100 mm of rainfall was recorded. Remaining trajectories were grouped into 5 clusters using an angle-based distance matrix based upon Sirois and Bottenheim (1995) through the openair package for R. Within-cluster frequencies were extracted and compared against the Nino3.4 index to determine possible spatial modulation by ENSO. A single outlier was removed from the Point Lookout trajectory dataset, with the trajectory associated with the rainfall event on 26/04/1956 consistently biasing the clustering calculations.

*A note on NCEP/NCAR reanalysis data* The NCEP/NCAR reanalysis data is reasonably coarse but as the focus is on large (>100mm) events driven by (presumably) synoptic-scale dynamics, this product should be appropriate. There is some fairly severe uncertainty in the NCEP/NCAR reanalysis prior to the late 1970s (erroneous inverted integration of SH pressure buoy data).

```{r rainfall-data-crunching, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE, fig.show = 'hide'}
## Section notes
# Rainfall data crunching including figuring out how to handle >100 mm rainfall events if they are spanning multiple days. 

## Get data: BOM Rainfall data
## SC
# SC_rainfall_data <- read.csv(paste0(proj_dir,"data/BOM rainfall/SandyCape_Data.csv"), header = TRUE) %>%
#   mutate(Month_seq = cumsum(c(0, as.numeric(diff(Month)) != 0)) + 1) %>%
#   mutate(rnum = seq.int(nrow(.))) %>%
#   ymd_similar()
# write_delim(SC_rainfall_data,file = paste0(proj_dir,"data/BOM rainfall/SC_rainfall_fmt.txt"),
#             delim = "\t")
SC_rainfall_data <- read.delim(file = paste0(proj_dir,"data/BOM rainfall/SC_rainfall_fmt.txt"),
            sep = "\t") %>%
  filter(Year >= 1950) %>%
  filter(Year <= 2023)
## PL
# PL_rainfall_data <- read.csv(paste0(proj_dir, "data/BOM rainfall/PointLookout_Data.csv"), header = TRUE)
# PLB_rainfall_data <- read.csv(paste0(proj_dir,"data/BOM rainfall/PointLookout_Bowls_Data.csv"), header = TRUE)
## Point Lookout combined. <1997 is bowls club, more recent is the PL station. 
# BOM_PLB_toadd <- PLB_rainfall_data[PLB_rainfall_data$Year <= 1996,]
# PLCombined_rainfall_data <- rbind(BOM_PLB_toadd,PL_rainfall_data) %>%
#   mutate(Month_seq = cumsum(c(0, as.numeric(diff(Month)) != 0)) + 1) %>%
#   mutate(rnum = seq.int(nrow(.))) %>%
#   ymd_similar()
# write_delim(PLCombined_rainfall_data,file = paste0(proj_dir,"data/BOM rainfall/PLCombined_rainfall_fmt.txt"),
#             delim = "\t")
PLCombined_rainfall_data <- read.delim(file = paste0(proj_dir,"data/BOM rainfall/PLCombined_rainfall_fmt.txt"),
            sep = "\t") %>%
  filter(Year >= 1950) %>%
  filter(Year <= 2023)
## Dunwich
# DW_rainfall_data <- read.csv(paste0(proj_dir,"data/BOM rainfall/Dunwich_Data.csv"), header = TRUE) %>%
#   mutate(Month_seq = cumsum(c(0, as.numeric(diff(Month)) != 0)) + 1) %>%
#   mutate(rnum = seq.int(nrow(.))) %>%
#   ymd_similar()
# write_delim(DW_rainfall_data,file = paste0(proj_dir,"data/BOM rainfall/DW_rainfall_fmt.txt"),
#             delim = "\t")
# DW_rainfall_data <- read.delim(file = paste0(proj_dir,"data/BOM rainfall/DW_rainfall_fmt.txt"),
#             sep = "\t") %>%
#   filter(Year >= 1950) %>%
#   filter(Year <= 2023)
# DW_100mm <- DW_rainfall_data %>%
#   filter(Rainfall.amount..millimetres. >= 100) %>%
#   # filter(Period.over.which.rainfall.was.measured..days. > 1) %>%
#   mutate(date_yyyymmdd = lubridate::ymd(date_yyyymmdd)) 

### CALCULATIONS FOR ADJACENT DAYS AND MULTI-DAY MEASUREMENTS
## Here we parse the identify 1) adjacent days where totals >100mm, and 2) where collections 
# were made over many days. 
# In the case of (1), pairs of days with >100 mm rainfall are identified after individual 100mm days
# are removed from the dataset. The larger of the paired measurements is chosen for the trajectory.
# For (2), rainfall totals are multiplied by (0.5*measurement duration) for instances where measurement
# duration is > 1 (i.e., a daily measurement was not made, and the measurement of the rain gauge was made
# after more than 1 day.)

## Adjustment needed.
# Need to identify how much rainfall is associated with each two-day event, so that the >100mm event sums are accurate.
# For this, need a per-event identifier (some sort of cumsum, then coerced to factor.)
# First: nested ifelse to fill in identifier for multi-day events (detect leading or lagging)
# Second: identifier for >100 mm single-day rainfall totals.
# Now there's a problem with the cumsum - the dual-day double identifiers are going to throw it.
# Cumsum at a change in value? I.e. only increase when there's a change from 1 to 0, rather than at every 1. 
# No, this assumes that there are gaps between events. Frustrating. 
# Could cumsum and then set to zero? Then just coerce numbers to the sequence.

# Re-thinking this. How about if the lag AND lead sums equal over 100, then 

## PL first
## Measurement period - this alters the rainfall totals to better reflect the mean per-day measurement.
## If a measurement is derived from a number of days >1, the total is divided by 2 to reflect the two-day window used 
## for event determination.
PLCombined_rainfall_data <- PLCombined_rainfall_data %>%
  mutate(mes_prd_adj = Period.over.which.rainfall.was.measured..days.) %>% 
  mutate(mes_prd_adj = ifelse(is.na(mes_prd_adj),
                          yes = 0,
                          no = mes_prd_adj)) %>% # Sets NAs to zero for the adjusted measurement period variable.
  mutate(Rainfall.amount..millimetres. = ifelse(mes_prd_adj > 1,
                                                yes = Rainfall.amount..millimetres./(mes_prd_adj/2),
                                                no = Rainfall.amount..millimetres.)) %>%
  mutate(mes_prd_adj = ifelse(mes_prd_adj > 1, 0.5 * mes_prd_adj, mes_prd_adj)) %>%
  mutate(exclude = ifelse(Rainfall.amount..millimetres. < 100 & mes_prd_adj > 1,
                          yes = 1,
                          no = 0)) %>%
  filter(exclude != 1) # Prevent the code below from incorporating averaged multi-day totals in the overall 
## Sequential days 
PLCombined_rainfall_data <- PLCombined_rainfall_data %>%
  ## First, perform a one-day lagged sum of daily rainfall totals.
  # mutate(seq_rain_lag = Rainfall.amount..millimetres. + lag(Rainfall.amount..millimetres., n = 1, default = 0)) %>%
  ## Next, generate a copy of the rainfall totals but set all 100mm days to zero so they don't bias subsequent lag calcs
  ## This is to avoid the situation where every single >100 mm day is identified as a multi-day event by the above (all 
  ## days with >=100mm will inevitably flag in the lagged average)
  mutate(rem_days_rfall = ifelse(Rainfall.amount..millimetres. >= 100,
                                 yes = 0,
                                 no = Rainfall.amount..millimetres.)) %>%
  # mutate(rem_days_rfall = Rainfall.amount..millimetres.) %>% # Keeping the name to prevent confusion
  ## Another lag sum, but ignoring >100mm single-day measurements.
  mutate(seq_rain_lag_remlg = rem_days_rfall + lag(rem_days_rfall, n = 1, default = 0))  %>%
  mutate(seq_rain_lead_remlg = rem_days_rfall + lead(rem_days_rfall, n = 1, default = 0))  %>%
  ## Now mark cases where either the individual day is over 100, or the adjusted lag sum is >100.
  mutate(lag_100 = ifelse(test = Rainfall.amount..millimetres. >= 100 | seq_rain_lag_remlg >= 100,
                          yes = 1,
                          no = 0)) %>%
  mutate(lead_100 = ifelse(test = Rainfall.amount..millimetres. >= 100 | seq_rain_lead_remlg >= 100,
                          yes = 1,
                          no = 0)) %>%
  mutate(event_flag = ifelse(lag_100 == 1 | lead_100 == 1,
                             yes = 2, 
                             no = 0)) %>%
  ## Do a simple lag sum of the lag flags.
  mutate(lag_100_dup = lag_100 + lag(lag_100)) %>%
  ## Identify cases where the sum equals 2, indicating adjacent lag_100 flags. Common if the mean mm across 3 days is >50 mm. The 'adjusted' lag 100 flag now isolates the largest days of two-day large falls.
  ## Is this really necessary?
  mutate(lag_100_adj = ifelse(lag_100_dup == 2,
                              yes = 0,
                              no = lag_100)) %>%
  ## Double-confirm all 100 day individual events are accounted for
  mutate(lag_100_adj = ifelse(Rainfall.amount..millimetres. >= 100,
                              yes = 1,
                              no = lag_100_adj)) %>%
  # Add an event flag to signify events, separate lag_100_adj var, which signposts the dates for trajectory-event matching.
  # Flag is 1 for single-day, 2 for multi-day.
  mutate(event_flag = ifelse(Rainfall.amount..millimetres. >= 100,
                                         yes = 1,
                                         no = event_flag))# %>%
  # dplyr::select(-c(lag_100_dup,lag_100,rem_days_rfall)) 
## Adjust pairings so largest day of the two is selected for the 100mm day identification
PLCombined_rainfall_data <- PLCombined_rainfall_data %>%
  mutate(test_half = ifelse(lag_100_adj == 1 & (Rainfall.amount..millimetres. < 0.5*seq_rain_lag_remlg),
                            yes = 1,
                            no = 0))
# Get the rownumbers of these.
PLCombined_rainfall_data <- PLCombined_rainfall_data %>%
  mutate(rnum = seq(1,nrow(.),1))
rows_to_0 = PLCombined_rainfall_data$rnum[which(PLCombined_rainfall_data$test_half == 1)]
rows_to_1 = rows_to_0 - 1
PLCombined_rainfall_data$lag_100_adj[rows_to_0] <- 0
PLCombined_rainfall_data$lag_100_adj[rows_to_1] <- 1
PLCombined_rainfall_data <- PLCombined_rainfall_data %>% dplyr::select(-c(test_half))


## SC
## Multi-day events
SC_rainfall_data <- SC_rainfall_data %>%
  mutate(mes_prd_adj = Period.over.which.rainfall.was.measured..days.) %>% 
  mutate(mes_prd_adj = ifelse(is.na(mes_prd_adj),
                          yes = 0,
                          no = mes_prd_adj)) %>% # Sets NAs to zero for the adjusted measurement period variable.
  mutate(Rainfall.amount..millimetres. = ifelse(mes_prd_adj > 1,
                                                yes = Rainfall.amount..millimetres./(mes_prd_adj/2),
                                                no = Rainfall.amount..millimetres.)) %>%
  mutate(mes_prd_adj = ifelse(mes_prd_adj > 1, 0.5 * mes_prd_adj, mes_prd_adj)) %>%
  mutate(exclude = ifelse(Rainfall.amount..millimetres. < 100 & mes_prd_adj > 1,
                          yes = 1,
                          no = 0)) %>%
  filter(exclude != 1) 
## Sequential days
SC_rainfall_data <- SC_rainfall_data %>%
  ## First, perform a one-day lagged sum of daily rainfall totals.
  # mutate(seq_rain_lag = Rainfall.amount..millimetres. + lag(Rainfall.amount..millimetres., n = 1, default = 0)) %>%
  ## Next, generate a copy of the rainfall totals but set all 100mm days to zero so they don't bias subsequent lag calcs
  ## This is to avoid the situation where every single >100 mm day is identified as a multi-day event by the above (all 
  ## days with >=100mm will inevitably flag in the lagged average)
  mutate(rem_days_rfall = ifelse(Rainfall.amount..millimetres. >= 100,
                                 yes = 0,
                                 no = Rainfall.amount..millimetres.)) %>%
  # mutate(rem_days_rfall = Rainfall.amount..millimetres.) %>% # Keeping the name to prevent confusion
  ## Another lag sum, but ignoring >100mm single-day measurements.
  mutate(seq_rain_lag_remlg = rem_days_rfall + lag(rem_days_rfall, n = 1, default = 0))  %>%
  mutate(seq_rain_lead_remlg = rem_days_rfall + lead(rem_days_rfall, n = 1, default = 0))  %>%
  ## Now mark cases where either the individual day is over 100, or the adjusted lag sum is >100.
  mutate(lag_100 = ifelse(test = Rainfall.amount..millimetres. >= 100 | seq_rain_lag_remlg >= 100,
                          yes = 1,
                          no = 0)) %>%
  mutate(lead_100 = ifelse(test = Rainfall.amount..millimetres. >= 100 | seq_rain_lead_remlg >= 100,
                          yes = 1,
                          no = 0)) %>%
  mutate(event_flag = ifelse(lag_100 == 1 | lead_100 == 1,
                             yes = 2, 
                             no = 0)) %>%
  ## Do a simple lag sum of the lag flags.
  mutate(lag_100_dup = lag_100 + lag(lag_100)) %>%
  ## Identify cases where the sum equals 2, indicating adjacent lag_100 flags. Common if the mean mm across 3 days is >50 mm. The 'adjusted' lag 100 flag now isolates the largest days of two-day large falls.
  ## Is this really necessary?
  mutate(lag_100_adj = ifelse(lag_100_dup == 2,
                              yes = 0,
                              no = lag_100)) %>%
  ## Double-confirm all 100 day individual events are accounted for
  mutate(lag_100_adj = ifelse(Rainfall.amount..millimetres. >= 100,
                              yes = 1,
                              no = lag_100_adj)) %>%
  # Add an event flag to signify events, separate lag_100_adj var, which signposts the dates for trajectory-event matching.
  # Flag is 1 for single-day, 2 for multi-day.
  mutate(event_flag = ifelse(Rainfall.amount..millimetres. >= 100,
                                         yes = 1,
                                         no = event_flag))# %>%
  # dplyr::select(-c(lag_100_dup,lag_100,rem_days_rfall)) 
## Adjust pairings so largest day of the two is selected for the 100mm day identification
SC_rainfall_data <- SC_rainfall_data %>%
  mutate(test_half = ifelse(lag_100_adj == 1 & (Rainfall.amount..millimetres. < 0.5*seq_rain_lag_remlg),
                            yes = 1,
                            no = 0))
# Get the rownumbers of these.
SC_rainfall_data <- SC_rainfall_data %>%
  mutate(rnum = seq(1,nrow(.),1))
rows_to_0 = SC_rainfall_data$rnum[which(SC_rainfall_data$test_half == 1)]
rows_to_1 = rows_to_0 - 1
SC_rainfall_data$lag_100_adj[rows_to_0] <- 0
SC_rainfall_data$lag_100_adj[rows_to_1] <- 1
SC_rainfall_data <- SC_rainfall_data %>% dplyr::select(-c(test_half))

## Ok, these should give us our 100mm days, corrected for long collection periods and two-day transient events.


# Test sums.
PL_100mm <- PLCombined_rainfall_data %>% filter(event_flag != 0)  %>% 
  mutate(date_diff = difftime(date_yyyymmdd,lag(date_yyyymmdd)) %>% as.numeric()) %>%
  mutate(event_id = event_identifier(.)) %>%
  group_by(event_id) %>%
  mutate(event_rainfall = sum(Rainfall.amount..millimetres.)) %>%
  mutate(maxr = ifelse(Rainfall.amount..millimetres. == max(Rainfall.amount..millimetres.),
                       yes = 1,
                       no = 0)) %>%# This ensures the date chosen is the highest rainfall day within each event.
  ungroup() %>%
  filter(maxr == 1) %>%
  dplyr::select(-c(exclude,rem_days_rfall,seq_rain_lag_remlg,seq_rain_lead_remlg,lag_100,lead_100,lag_100_dup,lag_100_adj,date_diff,lag_100_adj,maxr)) %>%
  filter(Year <= 2022)

SC_100mm <- SC_rainfall_data %>% filter(event_flag != 0)  %>% 
  mutate(date_diff = difftime(date_yyyymmdd,lag(date_yyyymmdd)) %>% as.numeric()) %>%
  mutate(event_id = event_identifier(.)) %>%
  group_by(event_id) %>%
  mutate(event_rainfall = sum(Rainfall.amount..millimetres.)) %>%
  mutate(maxr = ifelse(Rainfall.amount..millimetres. == max(Rainfall.amount..millimetres.),
                       yes = 1,
                       no = 0)) %>% # This ensures the date chosen is the highest rainfall day within each event.
  ungroup() %>%
  filter(maxr == 1) %>%
  dplyr::select(-c(exclude,rem_days_rfall,seq_rain_lag_remlg,seq_rain_lead_remlg,lag_100,lead_100,lag_100_dup,lag_100_adj,date_diff,lag_100_adj,maxr)) %>%
  filter(Year <= 2022)

  



# PL_100mm <- PLCombined_rainfall_data %>% filter(lag_100_adj == 1)
# SC_100mm <- SC_rainfall_data %>% filter(lag_100_adj == 1)

## Previous code for event identification sort
# ## First, rainfall parsing
# ## Add an index
# PLCombined_rainfall_data$rnum <- seq.int(nrow(PLCombined_rainfall_data))
# SC_rainfall_data$rnum <- seq.int(nrow(SC_rainfall_data))
# SC_rainfall_data <- ymd_similar(SC_rainfall_data)
# PLCombined_rainfall_data <- ymd_similar(PLCombined_rainfall_data)

## Sort for large rainfall events (>100mm)
## SC
# SC_100mm <- SC_rainfall_data[which(!is.na(SC_rainfall_data$Rainfall.amount..millimetres.)),]
# SC_100mm <- SC_100mm[which(SC_100mm$Rainfall.amount..millimetres. >= 100),]
## PL
# PL_100mm <- PLCombined_rainfall_data[which(!is.na(PLCombined_rainfall_data$Rainfall.amount..millimetres.)),]
# PL_100mm <- PL_100mm[which(PL_100mm$Rainfall.amount..millimetres. >= 100),]

## Other rainfall data
# Monthly
# PL_monthly_rainfall <- PLCombined_rainfall_data %>%
#   group_by(Month_seq) %>%
#   summarise(month_mm = sum(Rainfall.amount..millimetres., na.rm = T), Year = unique(Year), Month = unique(Month)) %>% ungroup() %>%
#   mutate(yr_month = paste0(Year,"-",str_pad(Month,2,side = "left","0"))) %>%
#   mutate(month_seq = seq(1,nrow(.),1))
# SC_monthly_rainfall <- SC_rainfall_data %>%
#   group_by(Month_seq) %>%
#   summarise(month_mm = sum(Rainfall.amount..millimetres., na.rm = T), Year = unique(Year), Month = unique(Month))


```

```{r cluster-calcs, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE, fig.show = 'hide'}
## Section notes
# Cluster calculations for trajectories for both sites.
# First some (now single-hashed, but left here for posterity) cutting and dicing is done on the large, daily trajectory datasets to narrow them down to 100mm events for each site. These files are >100 MB so can't be uploaded to github; thus cut + diced data frames are saved as txt files. These are read in in the current version of the script and used for the clustering.

# ## Extract data which matches the dates of large rainfall events
SC_100mmRainfall_Trajectories <- SC_72hr1TPD2000m_Reanalysis[SC_72hr1TPD2000m_Reanalysis$date.start %in% ( SC_100mm$date_yyyymmdd),]

# test <- SC_100mmRainfall_Trajectories

PL_100mmRainfall_Trajectories <- PL_72hr1TPD2000m_Reanalysis[PL_72hr1TPD2000m_Reanalysis$date.start %in% ( PL_100mm$date_yyyymmdd),]
## Restructuring for cluster analysis
SC_trimtraj <- format_for_openair(SC_100mmRainfall_Trajectories)
PL_trimtraj <- format_for_openair(PL_100mmRainfall_Trajectories)
## Removing outlier from Point lookout dataset
PL_trimtraj <- PL_trimtraj %>%
  filter(date != unique(PL_trimtraj$date[which(PL_trimtraj$lon < 115)]))
## Write to tab-delim .txt
write_delim(SC_trimtraj, file = paste0(proj_dir,'data/traj/SC_100mm_trajectories_cln.txt'),
            delim = '\t')
write_delim(PL_trimtraj, file = paste0(proj_dir,'data/traj/PL_100mm_trajectories_cln.txt'),
            delim = '\t')

## Read the 100mm tab-delim text files  for cluster analysis
SC_trimtraj <- read_delim(file = paste0(proj_dir,'data/traj/SC_100mm_trajectories_cln.txt'),
            delim = '\t', show_col_types = F) %>% 'rownames<-'(c(seq(1,nrow(.),1)))
PL_trimtraj <- read_delim(file = paste0(proj_dir,'data/traj/PL_100mm_trajectories_cln.txt'),
            delim = '\t', show_col_types = F) %>% 'rownames<-'(c(seq(1,nrow(.),1)))

## Performing cluster analysis
pl_4clus <- openair::trajCluster(traj = PL_trimtraj,
                                 method = "Angle",
                                 # orientation = c(90,0,160),
                                 n.cluster = 4,
                                 plot = FALSE)
sc_4clus <- openair::trajCluster(traj = SC_trimtraj,
                                 method = "Angle",
                                 # orientation = c(90,0,160),
                                 n.cluster = 4,
                                 plot = FALSE)

## Now need to recode these so that they're consistent visually in some manner.
## Going to name them based on direction.
## Nested ifelse (I apologise).
# results frames
sc_4clus$data$results <- sc_4clus$data$results %>%
  mutate(cluster = ifelse(cluster == "C2",
                          yes = "C-NE",
                          no = ifelse(cluster =="C4",
                                      yes = "C-W",
                                      no = ifelse(cluster == "C1",
                                                  yes = "C-E",
                                                  no = ifelse(cluster == "C3",
                                                              yes = "C-N",
                                                              no = cluster)))))
pl_4clus$data$results <- pl_4clus$data$results %>%
  mutate(cluster = ifelse(cluster == "C3",
                          yes = "C-N",
                          no = ifelse(cluster =="C1",
                                      yes = "C-E",
                                      no = ifelse(cluster == "C4",
                                                  yes = "C-S",
                                                  no = ifelse(cluster == "C2",
                                                              yes = "C-W",
                                                              no = cluster)))))
# Trajectory frames inside the openair results
sc_4clus$data$traj <- sc_4clus$data$traj %>%
  mutate(cluster = ifelse(cluster == "C2",
                          yes = "C-NE",
                          no = ifelse(cluster =="C4",
                                      yes = "C-W",
                                      no = ifelse(cluster == "C1",
                                                  yes = "C-E",
                                                  no = ifelse(cluster == "C3",
                                                              yes = "C-N",
                                                              no = cluster)))))
pl_4clus$data$traj <- pl_4clus$data$traj %>%
  mutate(cluster = ifelse(cluster == "C3",
                          yes = "C-N",
                          no = ifelse(cluster =="C1",
                                      yes = "C-E",
                                      no = ifelse(cluster == "C4",
                                                  yes = "C-S",
                                                  no = ifelse(cluster == "C2",
                                                              yes = "C-W",
                                                              no = cluster)))))

```

Nino 3.4 SST anomaly data at monthly resolution was obtained [from NOAA](https://psl.noaa.gov/data/correlation/nina34.anom.data). Phase events (i.e. La Nina, El Nino, or neutral) were defined based on the [definition utilised by NOAA](https://www.ncei.noaa.gov/access/monitoring/enso/sst). That is, an El Nino event is a time period where the three-month-averaged-smoothed Nino3.4 anomaly timeseries exceeds a value of 0.5 for 5 months or more. La Nina, where the value falls below -0.5 for >5 months. A neutral period is used here to denote any time period where there is no El Nino or La Nina event occuring, as per the definition. 

NINO3.4 time series

```{r ENSO-timeseries, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 3, fig.width = 14, units = cm}
## Section notes
# Making a plot of ENSO

# Nino data wrangling
nino_forplot <- Nino3.4 %>% 
  filter(Year >= 1950) %>%
  filter(Year <= 2023) %>%
  mutate(month_seq = seq(1,nrow(.),1)) %>%
  # mutate(ym = 0) %>%
  ## Detecting el nino and la nina events
## Definition from NOAA (https://www.ncei.noaa.gov/access/monitoring/enso/sst): 5 months of 3-month ma series exceeding/falling below anomaly threshold.
  mutate(Over.5 = ifelse(ma(Nino3.4,3) > 0.5,
                         yes = 1,
                         no = 0)) %>%
  mutate(Under.5 = ifelse(ma(Nino3.4,3) < -0.5,
                          yes = 1,
                          no = 0)) 

# Code here from https://stackoverflow.com/questions/50107771/how-to-find-consecutive-values-2-with-length-3-in-r
# Praise be to stack overflow
# Find positions of La Nina episodes
out <- data.frame(unclass(rle(as.vector(nino_forplot$Under.5) == 1)))
out$pos <- head(cumsum(c(1, out$lengths)), -1)
LaNinaEps = out[out$lengths>=5  & out$values,c("pos", "lengths")]
# And now el nino
out <- data.frame(unclass(rle(as.vector(nino_forplot$Over.5) == 1)))
out$pos <- head(cumsum(c(1, out$lengths)), -1)
ElNinoEps = out[out$lengths>=5  & out$values,c("pos", "lengths")]
# How to make these into polygons?
# Need start and end for each polygon. 
El_Nino_polys <- data.frame(matrix(NA,nrow = nrow(ElNinoEps), ncol = 4)) %>%
  'colnames<-'(c('xmin','xmax','ymin','ymax'))
El_Nino_polys$xmin = ElNinoEps$pos
El_Nino_polys$xmax = ElNinoEps$pos + ElNinoEps$lengths
El_Nino_polys$ymin = -2.6
El_Nino_polys$ymax = 2.6
# And la nina
La_Nina_polys <- data.frame(matrix(NA,nrow = nrow(LaNinaEps), ncol = 4)) %>%
  'colnames<-'(c('xmin','xmax','ymin','ymax'))
La_Nina_polys$xmin = LaNinaEps$pos
La_Nina_polys$xmax = LaNinaEps$pos + LaNinaEps$lengths
La_Nina_polys$ymin = -2.6
La_Nina_polys$ymax = 2.6

## ggplot block
ggplot() + 
  # hlines
  geom_hline(yintercept = 0, linetype = 'solid', colour = 'black') +
  geom_hline(yintercept = c(-0.5,0.5), linetype = 'dashed', colour = c("blue","red")) +
  # ENSO polygons
  geom_rect(data = El_Nino_polys, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), fill = 'red', alpha = 0.3) +
  geom_rect(data = La_Nina_polys, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), fill = 'blue', alpha = 0.3) +
  # Nino3.4
  geom_line(data = nino_forplot, aes(x = month_seq, y = ma(Nino3.4,3)), size = 0.25) +
  # difference polygons using ggh4x. This doesn't like 0 for some reason
  stat_difference(data = nino_forplot, aes(x = month_seq, ymin = 0.00000001, ymax = ma(Nino3.4,3))) +
  # annotations
  annotate(geom = 'text', 
           label = 'Cold SST; La Nina', 
           x = nino_forplot$month_seq[which(nino_forplot$Year %% 1954 == 0)[1]], 
           y = -2.3) +
  annotate(geom = 'text', 
           label = 'Warm SST; El Nino', 
           x = nino_forplot$month_seq[which(nino_forplot$Year %% 1954 == 0)[1]], 
           y = 2.3) +
  scale_fill_manual(
    values = c("red", "blue"),
    guide = "none") +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0, max(nino_forplot$month_seq)),
                     breaks = c(0,nino_forplot$month_seq[which(nino_forplot$month_seq %% (12*5) == 0)]),
                     labels = c(1950, 1950 + nino_forplot$month_seq[which(nino_forplot$month_seq %% (12*5) == 0)]/12)) +
  scale_y_continuous(expand = c(0,0), limits = c(-2.6,2.6)) +
  # theme_cowplot(12) +
  theme_cowplot(12) +
  labs(x = "Year", y = "Nino 3.4 anomalies") +
  theme(plot.margin = margin(7,14,7,7))

### TIFF EXPORT
## Save as tiff (unhash and run scaling vars, tiff command, ggplot block, and dev off segment, all as a group)
# wd = 14
# hgt = 3
# scaling = 1
# tiff(paste0(tiff_dir,"ENSO-phases.tiff"),
#      units = "cm",
#      width = wd * scaling, height = hgt * scaling,
#      res = 300)
# ann_size = textsize_vsmall/.pt/.pt  
## ggplot block
# ggplot() + 
#   # hlines
#   geom_hline(yintercept = 0, linetype = 'solid', colour = 'black', size = 0.25) +
#   geom_hline(yintercept = c(-0.5,0.5), linetype = 'dashed', colour = c("blue","red"), size = 0.25) +
#   # ENSO polygons
#   geom_rect(data = El_Nino_polys, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), fill = 'red', alpha = 0.3) +
#   geom_rect(data = La_Nina_polys, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), fill = 'blue', alpha = 0.3) +
#   # Nino3.4
#   geom_line(data = nino_forplot, aes(x = month_seq, y = ma(Nino3.4,3)), size = 0.25) +
#   # difference polygons using ggh4x. This doesn't like 0 for some reason
#   stat_difference(data = nino_forplot, aes(x = month_seq, ymin = 0.00000001, ymax = ma(Nino3.4,3))) +
#   # annotations
#   annotate(geom = 'text', 
#            label = 'Cold SST; La Nina', 
#            x = nino_forplot$month_seq[which(nino_forplot$Year %% 1955 == 0)[1]], 
#            y = -2.2,
#            size = ann_size) +
#   annotate(geom = 'text', 
#            label = 'Warm SST; El Nino', 
#            x = nino_forplot$month_seq[which(nino_forplot$Year %% 1955 == 0)[1]], 
#            y = 2.2,
#            size = ann_size) +
#   scale_fill_manual(
#     values = c("red", "blue"),
#     guide = "none") +
#   scale_x_continuous(expand = c(0,0),
#                      limits = c(0, max(nino_forplot$month_seq)),
#                      breaks = c(0,nino_forplot$month_seq[which(nino_forplot$month_seq %% (12*5) == 0)]),
#                      labels = c(1950, 1950 + nino_forplot$month_seq[which(nino_forplot$month_seq %% (12*5) == 0)]/12)) +
#   scale_y_continuous(expand = c(0,0), limits = c(-2.6,2.6)) +
#   # theme_cowplot(12) +
#   theme_tiff(textsize_vsmall/.pt) +
#   labs(x = "Year", y = "Nino 3.4 anomalies") +
#   theme(plot.margin = margin(7,14,7,7))

# while (!is.null(dev.list()))  dev.off()

```

Fig. ENSO time series used for phase event definition.

Rainfall time series

```{r rainfall-timeseries, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 11, fig.width = 14, units = cm}
## Section notes
# Timeseries of rainfall data with ENSO

## Monthly
# PL
PL_monthly_rainfall <- PLCombined_rainfall_data %>%
  group_by(Month_seq) %>%
  summarise(month_mm = sum(Rainfall.amount..millimetres., na.rm = T), Year = unique(Year), Month = unique(Month)) %>% ungroup() %>%
  mutate(yr_month = paste0(Year,"-",str_pad(Month,2,side = "left","0"))) %>%
  mutate(month_seq = seq(1,nrow(.),1))
# SC
SC_monthly_rainfall <- SC_rainfall_data %>%
  group_by(Month_seq) %>%
  summarise(month_mm = sum(Rainfall.amount..millimetres., na.rm = T), Year = unique(Year), Month = unique(Month)) %>% ungroup() %>%
  mutate(yr_month = paste0(Year,"-",str_pad(Month,2,side = "left","0"))) %>%
  mutate(month_seq = seq(1,nrow(.),1))
## Annual
# PL
PL_annual_rain <- PL_monthly_rainfall %>%
  group_by(Year) %>%
  summarise(ann_rain = sum(month_mm)) %>%
  arrange(Year)
PL_annrain_stepfmt <- rbind(PL_annual_rain,PL_annual_rain[nrow(PL_annual_rain),])
PL_annrain_stepfmt$Year[75] <- 2024
# SC
SC_annual_rain <- SC_monthly_rainfall %>%
  group_by(Year) %>%
  summarise(ann_rain = sum(month_mm)) %>%
  arrange(Year) 
SC_annrain_stepfmt <- rbind(SC_annual_rain,SC_annual_rain[nrow(SC_annual_rain),])
SC_annrain_stepfmt$Year[75] <- 2024

## Annual rainfall coerced to month_seq scale
# PL
PL_annual_rain_monthly <- data.frame(matrix(NA, ncol = 13, nrow = nrow(PL_annual_rain))) 
PL_annual_rain_monthly[,1] <- PL_annual_rain$Year
PL_annual_rain_monthly[,2:13] <- PL_annual_rain$ann_rain 
colnames(PL_annual_rain_monthly) <- c('Year',seq(1,12,1))
PL_annual_rain_monthly <- PL_annual_rain_monthly %>%
  pivot_longer(., cols = c(2:13), names_to = 'month', values_to = 'rain_mm') %>%
  mutate(month_seq = seq(1,nrow(.),1))
# SC
SC_annual_rain_monthly <- data.frame(matrix(NA, ncol = 13, nrow = nrow(SC_annual_rain))) 
SC_annual_rain_monthly[,1] <- SC_annual_rain$Year
SC_annual_rain_monthly[,2:13] <- SC_annual_rain$ann_rain 
colnames(SC_annual_rain_monthly) <- c('Year',seq(1,12,1))
SC_annual_rain_monthly <- SC_annual_rain_monthly %>%
  pivot_longer(., cols = c(2:13), names_to = 'month', values_to = 'rain_mm') %>%
  mutate(month_seq = seq(1,nrow(.),1))

## PLOTS: Sandy Cape
# Annual
SC_annual_rainplot <- ggplot() + 
  geom_vline(xintercept = c(0,SC_annual_rain_monthly$month_seq[which(SC_annual_rain_monthly$month_seq %% (12*5) == 0)]), linetype = 'dashed', colour = 'grey60') +
  geom_step(data = SC_annual_rain_monthly, aes(x = month_seq - 1, y = rain_mm)) +
  scale_x_continuous(expand = c(0,0), 
                     limits = c(0,max(SC_annual_rain_monthly$month_seq)), 
                     breaks = c(0,SC_annual_rain_monthly$month_seq[which(SC_annual_rain_monthly$month_seq %% (12*5) == 0)]),
                     labels = c(1950, 1950 + SC_annual_rain_monthly$month_seq[which(SC_annual_rain_monthly$month_seq %% (12*5) == 0)]/12), position = 'top') +
  scale_y_continuous(expand = c(0,0), limits = c(300,2700), breaks = seq(500,2500,500), position = 'left') +
  # ggtitle("Sandy Cape") +
  annotate(geom = 'text', label = 'Sandy Cape', 
           x = max(SC_annual_rain_monthly$month_seq)/2,
           y = 2500) +
  theme_cowplot(12) +
  labs(x = "Year", y = "SC Annual rainfall (mm)") +
  # theme_rem_xaxis +
  theme(plot.title = element_text(hjust = 0.5),
        plot.margin = margin(7,7,-2,7))
# Monthly
SC_monthly_rainplot <- ggplot() + 
  geom_vline(xintercept = c(0,SC_monthly_rainfall$month_seq[which(SC_monthly_rainfall$month_seq %% (12*5) == 0)]), linetype = 'dashed', colour = 'grey60') + 
  geom_step(data = SC_monthly_rainfall, aes(x = month_seq, y = month_mm)) +
  scale_x_continuous(expand = c(0,0), 
                     limits = c(0,max(PL_monthly_rainfall$month_seq)), 
                     breaks = c(0,PL_monthly_rainfall$month_seq[which(PL_monthly_rainfall$month_seq %% (12*5) == 0)]),
                     labels = c(1950,1950 + PL_monthly_rainfall$month_seq[which(PL_monthly_rainfall$month_seq %% (12*5) == 0)]/12)) +
  scale_y_continuous(expand = c(0,0), limits = c(-10,800), breaks = seq(0,800,200), position = 'right') +
  theme_cowplot(12) +
  theme_rem_xaxis +
  labs(y = "SC Monthly rainfall (mm)") +
  theme(plot.margin = margin(0,7,-2,7))

## PLOTS: Point lookout
# Annual
PL_annual_rainplot <- ggplot() + 
  geom_vline(xintercept = c(0,PL_annual_rain_monthly$month_seq[which(PL_annual_rain_monthly$month_seq %% (12*5) == 0)]), linetype = 'dashed', colour = 'grey60') +
  geom_step(data = PL_annual_rain_monthly, aes(x = month_seq - 1, y = rain_mm)) +
  scale_x_continuous(expand = c(0,0), 
                     limits = c(0,max(PL_annual_rain_monthly$month_seq)), 
                     breaks = c(0,PL_annual_rain_monthly$month_seq[which(PL_annual_rain_monthly$month_seq %% (12*5) == 0)]),
                     labels = c(1950,1950 + PL_annual_rain_monthly$month_seq[which(PL_annual_rain_monthly$month_seq %% (12*5) == 0)]/12)) +
  scale_y_continuous(expand = c(0,0), limits = c(300,2700), breaks = seq(500,2500,500)) +
  # ggtitle("Point lookout") +
  annotate(geom = 'text', label = 'Point Lookout', 
           x = max(SC_annual_rain_monthly$month_seq)/2,
           y = 2500) +
  theme_cowplot(12) +
  labs(y = "PL Annual rainfall (mm)") +
  theme_rem_xaxis +
  theme(plot.title = element_text(hjust = 0.5),
        plot.margin = margin(0,7,-2,7))
# Monthly
PL_monthly_rainplot <- ggplot() + 
    geom_vline(xintercept = c(0,PL_monthly_rainfall$month_seq[which(PL_monthly_rainfall$month_seq %% (12*5) == 0)]), linetype = 'dashed', colour = 'grey60') +
  geom_step(data = PL_monthly_rainfall, aes(x = month_seq, y = month_mm)) +
  scale_x_continuous(expand = c(0,0), 
                     limits = c(0,max(PL_monthly_rainfall$month_seq)), 
                     breaks = c(0,PL_monthly_rainfall$month_seq[which(PL_monthly_rainfall$month_seq %% (12*5) == 0)]),
                     labels = c(1950,1950 + PL_monthly_rainfall$month_seq[which(PL_monthly_rainfall$month_seq %% (12*5) == 0)]/12)) +
  scale_y_continuous(expand = c(0,0), limits = c(-10,800), breaks = seq(0,800,200), position = 'right') +
  theme_cowplot(12) +
  labs(x = "Year", y = "PL Monthly rainfall (mm)") +
  theme(plot.margin = margin(0,7,7,7))

## Save as tiff (unhash and run scaling vars, tiff command, ggplot block, and dev off segment, all as a group). 
## NB: didn't revise the code to optimise this figure's TIFF export as it isn't one of the key figures.
# hgt = 11
# wd = 14
# scaling = 2.5
# tiff(paste0(tiff_dir,"Rainfall-timeseries.tiff"),
#      units = "cm",
#      width = wd * scaling, height = hgt * scaling,
#      res = 300)
## Combined plots
cowplot::plot_grid(SC_annual_rainplot,
                   SC_monthly_rainplot,
                   PL_annual_rainplot,
                   PL_monthly_rainplot,
                   nrow = 4, ncol = 1, align = 'v')

# while (!is.null(dev.list()))  dev.off()


```

Monthly and annual total rainfall for Sandy Cape and Point Lookout between 1950 and 2022.

To determine potential differences in the spatial dynamics of large event precipitation, trajectories from days where >100 mm of rain was recorded were grouped using cluster analysis. To prioritise the importance of backwards travel direction, and angle-based distance matrix calculation was used, based upon Sirois and Bottenheim (1995). Clustering was performed using the openair package in R. Four clusters were chosen in order to provide a balance between separation of disparate trajectories whilst not exacerbating the potential bias introduced by individual outlier trajectories as a result of the relatively small trajectory sample sizes (104 event trajectories for PL, 68 for SC). 

```{r cluster-path-plots, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 7, fig.width = 14, units = cm}
## Section notes
# Plotting the cluster pathways for each site.

twomap_scaling <- generate_plot_themes(14/.pt)

## Sandy cape

# Update plots with labels 
# From each cluster termination point, find the bearing to the sc or pl point


SC_clus_bearings <- clus_bearings(sc_4clus,
                                  c(SC_lon,SC_lat)) %>%
    mutate(nudgey = ifelse(bearing >= 315 | bearing <= 45, 2, 
                           ifelse(bearing >= 135 & bearing <= 225, -2, 0))) %>%
    mutate(nudgex = ifelse(bearing >= 45 & bearing <= 135, 4, 
                           ifelse(bearing >= 225 & bearing <= 315, -4, 0)))
PL_clus_bearings <- clus_bearings(pl_4clus,
                                  c(PL_lon,PL_lat)) %>%
    mutate(nudgey = ifelse(bearing >= 315 | bearing <= 45, 2, 
                           ifelse(bearing >= 135 & bearing <= 225, -2, 0))) %>%
    mutate(nudgex = ifelse(bearing >= 45 & bearing <= 135, 4, 
                           ifelse(bearing >= 225 & bearing <= 315, -4, 0)))

# Add label based on lat lon
add_clabels <- function(clus_bearings){
  clus_bearings <- clus_bearings %>%
    mutate(nudgey = ifelse(bearing >= 315 | bearing <= 45, 2, 
                           ifelse(bearing >= 135 & bearing <= 225, -2, 0))) %>%
    mutate(nudgex = ifelse(bearing >= 45 & bearing <= 135, 2, 
                           ifelse(bearing >= 225 & bearing <= 315, -2, 0)))
  clus_bearings
}

clus_sc_dat <- sc_4clus$data$results
sc_clusplot <- ggplot() +
  EastAus_Full_Basemap +
  geom_path(data = clus_sc_dat, aes(x = lon, y = lat, group = cluster), colour = "darkred",size = 0.25, alpha = 1) +
  geom_map(data = EastAus_Zoomout_Data, map = EastAus_Zoomout_Data,
           aes(x = long, y = lat, group = group, map_id = region),
           fill = "transparent", colour = "grey8", linewidth = 0.01) +
  # labs(title = "Sandy Cape >100mm rainfall event clusters (n = 5)") +
  geom_point(data = SC_point_df, aes(x = lon, y = lat), shape = 21, fill = "white", size = 2) +
    geom_label(data = SC_clus_bearings, 
               aes(x = lon + nudgex, y = lat + nudgey, label = paste0(cluster,": ",freq, "%")), size = textsize_vsmall/.pt/.pt) +
  twomap_scaling

## Point lookout
clus_pl_dat <- pl_4clus$data$results
pl_clusplot <- ggplot() +
  EastAus_Full_Basemap +
  geom_path(data = clus_pl_dat, aes(x = lon, y = lat, group = cluster), colour = "darkred",size = 0.25, alpha = 1) +
  geom_map(data = EastAus_Zoomout_Data, map = EastAus_Zoomout_Data,
           aes(x = long, y = lat, group = group, map_id = region),
           fill = "transparent", colour = "grey8", linewidth = 0.01) +
  # labs(title = "Point Lookout >100mm rainfall event clusters (n = 5)") +
  geom_label(data = PL_clus_bearings, 
             aes(x = lon + nudgex, y = lat + nudgey, label = paste0(cluster,": ",freq,"%")), size = textsize_vsmall/.pt/.pt) +
  geom_point(data = PL_point_df, aes(x = lon, y = lat), shape = 21, fill = "white", size = 2) +
  # theme_maps(font_size = textsize_vsmall/.pt/.pt) +
  twomap_scaling
## Tiff bits
hgt = 7
wd = 14
scaling = 1
tiff(paste0(tiff_dir,"Cluster-path-plots.tiff"),
     units = "cm",
     width = wd * scaling, height = hgt * scaling,
     res = 300)
## Combine
cowplot::plot_grid(sc_clusplot,
                   pl_clusplot,
                   nrow = 1, ncol = 2)

while (!is.null(dev.list()))  dev.off()

```

Fig. Trajectory clusters (n = 4) to Sandy Cape (left) and Point Lookout (right). Frequencies display the >100 mm within each cluster as a proportion of the total number at each site. Cluster names have no statistical significance and were designated to draw parity between each site where possible. Clusters are named based upon their approximate direction of travel. Note that this naming scheme (and any cluster designation method) is inherently and unavoidably reductive, and each cluster will be comprised of trajectories that, whilst similar spatially, will travel in different ways and from different directions. The clustering simply serves to reduce the dimensionality of the data in a meaningful way.

For the period of 2002 to present, daily BOM MSLP charts can be used to perform a very limited and selective interrogation of the behaviour of the model (i.e., are the pathways consistent with how we might expect airmasses to move along isobars).

On 29/03/22, ~240 mm of rain was recorded at Point Lookout. Inspecting the BOM MSLP charts for this period shows a front associated with a fast-moving low-pressure cell moving down to PL from the tropics.

```{r BOM-mslp-charts, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 7, fig.width = 14, units = cm}

library(magick)
library(cowplot)
library(ggplot2)

bom_img_dir <- paste0(proj_dir,"external images/")
img_files <- list.files(bom_img_dir, full.names = T)


p1 <- ggdraw() + draw_image(img_files[1], scale = 1)
p2 <- ggdraw() + draw_image(img_files[2], scale = 1)
p3 <- ggdraw() + draw_image(img_files[3], scale = 1)
p4 <- ggdraw() + draw_image(img_files[4], scale = 1)
p5 <- ggdraw() + draw_image(img_files[5], scale = 1)


## Tiff bits
# hgt = 7
# wd = 14
# scaling = 1
# tiff(paste0(tiff_dir,"BOM-MSLP-5panel.tiff"),
#      units = "cm",
#      width = wd * scaling, height = hgt * scaling,
#      res = 300)
## ggplot block
plot_grid(p1, p2, p3,
          p4, p5, NULL,
          nrow = 2, ncol = 3)
## Close null device for tiff export
# while (!is.null(dev.list()))  dev.off()



```

Fig. Five days of MSLP charts from BOM, 27/03/22 - 31/03/22.

The trajectories from this period all behave as we might expect, moving anti-clockwise around the  high-pressure cell over the Tasman sea, before being perturbed by the low-pressure cell when it arrives at point lookout. The event trajectory for 29/03/22 was classified into the 'C-E' cluster. 

```{r event-path-plots, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 7, fig.width = 7, units = cm}
## Section notes
## Plotting the cluster pathways for each site.
twomap_scaling <- generate_plot_themes(14/.pt)

## After the single event on 29 Mar 2022 as it has satellite and synoptic chart coverage
# PL_event_20220329 <- PL_72hr1TPD2000m_Reanalysis %>%
#   filter(date.start %in% c("2022-03-26","2022-03-27","2022-03-28","2022-03-29","2022-03-30","2022-03-31","2022-04-01","2022-04-02"))

## Saving as tab delim text
# write_delim(PL_event_20220329, 
#             file = paste0(proj_dir,"data/traj/PL_event_20220329.txt"),
#             delim = "\t")

## Reading back in
PL_event_20220329 <- read_delim(file = paste0(proj_dir,"data/traj/PL_event_20220329.txt"),
                                delim = "\t",
                                show_col_types = F)

# Plot the event
event_plot <- ggplot() +
  EastAus_Full_Basemap +
  geom_path(data = PL_event_20220329, aes(x = lon, y = lat, group = as.factor(trajectory), colour = as.factor(trajectory)), size = 0.5, alpha = 1) +
  geom_map(data = EastAus_Zoomout_Data, map = EastAus_Zoomout_Data,
           aes(x = long, y = lat, group = group, map_id = region),
           fill = "transparent", colour = "grey8", size = 0.2) +
  scale_colour_brewer(name = 'YlGnBu', direction = -1,
                      labels = c("2022-03-26","2022-03-27","2022-03-28","2022-03-29","2022-03-30","2022-03-31","2022-04-01","2022-04-02")) +
  guides(color = guide_legend("Date",
                              override.aes = list(size = 0.5))) +
  theme(#legend.position = 'inside',
        #legend.position.inside = c(0.2,0.4),
        legend.text = element_text(size =  textsize_vsmall/.pt),
        legend.title = element_text(size = textsize_small/.pt),
        legend.margin = margin(1,1,1,1),
      legend.spacing.x = unit(0, "mm"),
      legend.spacing.y = unit(0, "mm")) +
    geom_point(data = PL_point_df, aes(x = lon, y = lat), shape = 21, fill = "white", size = 2) +
  twomap_scaling
  # guides(colour = guide_legend(override.aes = list(size = 0.5)))

## Tiff bits
hgt = 7
wd = 10
scaling = 1
# tiff(paste0(tiff_dir,"Event-path-plot.tiff"),
#      units = "cm",
#      width = wd * scaling, height = hgt * scaling,
#      res = 300)
## Display
event_plot
## Close null device for tiff export
# while (!is.null(dev.list()))  dev.off()

```

Fig. Daily trajectory paths between 26/03/22 and 02/04/22. Lighter colours = later days.

Hidden code block here for cluster time series WIP code. Insufficient sample size to do anything interesting at this stage.

```{r cluster-freq-timeseries, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 3, fig.width = 14, units = cm}
## Section notes
# Trajectory frequency assessments


# What are we actually trying to do here?
# I want to know how they vary through time. Or... do I? Through time doesn't really matter; we're after overall trends.

# So, skip these!
# Hashing out this code for now.

# Extract cluster frequencies
pl_4clus_freqseries <- pl_4clus$data$traj %>%
        filter(hour.inc == 0) %>%
        group_by(year, cluster) %>%
        summarise(n = n()) %>%
        mutate(freq = n / sum(n)) %>%
        ungroup()
sc_4clus_freqseries <- sc_4clus$data$traj %>%
        filter(hour.inc == 0) %>%
        group_by(year, cluster) %>%
        summarise(n = n()) %>%
        mutate(freq = n / sum(n)) %>%
        ungroup()
# Looping PL 
## This currently conflates an entry of n as n. n can be greater than 1 if more than one event occurs in a year.
# Which... do I account for sequential days in my event considerations? What if an event is so large it causes rain across multiple days? Could this account for some differences between the two sites in terms of n/freq?

# Get dates of PL C-W events
# CW; all different days.
PL_CW_events <- pl_4clus$data$traj %>%
  filter(cluster == "C-W") %>%
  filter(hour.inc == -1)
# CN; Yes. 1974-01-24 and 1974-01-25
PL_CN_events <- pl_4clus$data$traj %>%
  filter(cluster == "C-N") %>%
  filter(hour.inc == -1)
# CS; 1972-03-05 and 1972-03-07
PL_CS_events <- pl_4clus$data$traj %>%
  filter(cluster == "C-S") %>%
  filter(hour.inc == -1)
# CE; Yes. 1980-05-05 and and 1980-05-06. 1996-05-01 and 1996-05-03. 2021-03-20 and 2021-03-22. 2022-02-25 and 2022-02-26.
PL_CE_events <- pl_4clus$data$traj %>%
  filter(cluster == "C-E") %>%
  filter(hour.inc == -1)

## And now SC
# CW; all different days.
SC_CW_events <- sc_4clus$data$traj %>%
  filter(cluster == "C-W") %>%
  filter(hour.inc == -1)
# CN; Yes. 1980-02-05 and 1980-02-06
SC_CN_events <- sc_4clus$data$traj %>%
  filter(cluster == "C-N") %>%
  filter(hour.inc == -1)
# CNE; all different days
SC_CNE_events <- sc_4clus$data$traj %>%
  filter(cluster == "C-NE") %>%
  filter(hour.inc == -1)
# CE; Yes. 1970-01-29 and 1970-01-30. 1995-02-11 and 1995-02-13. 1996-04-22 and 1996-04-24. 2020-03-08 and 2020-03-09.
SC_CE_events <- sc_4clus$data$traj %>%
  filter(cluster == "C-E") %>%
  filter(hour.inc == -1)

# So, PL has six potentially 'duplicated' large events where rainfall was received over two days. Most of these are found in the 'C-E' cluster.
# SC has 5, with most in the C-E cluster as well. None of the dates are the same.

# Can probably conclude that this is a relatively minor factor. Large, multi-day events will just exert a slight bias on the clustering.
# 
# 
# pl_freq_list <- vector('list', length = length(unique(pl_4clus_freqseries$cluster))) %>%
#   'names<-'(c(unique(pl_4clus_freqseries$cluster)))
# for(c in seq_along(pl_freq_list)){
#   #
#   c = 2
#   #
#   
#   this_clus <- unique(pl_4clus_freqseries$cluster)[c]
#   empty_dat <- data.frame(year = seq(1950,2022,1),
#                           cluster = this_clus)
#   this_data <- pl_4clus_freqseries %>%
#     filter(cluster == this_clus) %>%
#     full_join(empty_dat) %>%
#     replace(is.na(.), 0) %>%
#     arrange(year)
#   pl_freq_list[[c]] <- this_data
# }
# # Looping SC
# sc_freq_list <- vector('list', length = length(unique(sc_4clus_freqseries$cluster))) %>%
#   'names<-'(c(unique(sc_4clus_freqseries$cluster)))
# for(c in seq_along(sc_freq_list)){
#   this_clus <- unique(sc_4clus_freqseries$cluster)[c]
#   empty_dat <- data.frame(year = seq(1950,2022,1),
#                           cluster = this_clus)
#   this_data <- sc_4clus_freqseries %>%
#     filter(cluster == this_clus) %>%
#     full_join(empty_dat) %>%
#     replace(is.na(.), 0) %>%
#     arrange(year)
#   sc_freq_list[[c]] <- this_data
# }
# 
# # ggplot() +
# #   geom_step(data = pl_4clus_freqseries, aes(x = year - 0.5, y = freq))
# 
# 
# 
# ## Plot it all together I guess
# pl_CN_n <- ggplot() +
#    geom_vline(xintercept = seq(1950,2020,5), linetype = 'dashed', colour = 'grey60') +
#    geom_step(data = pl_freq_list$`C-N`, aes(x = year, y = n)) +
#    scale_x_continuous(expand = c(0,0), limits = c(1950,2022), breaks = seq(1950,2020,10)) +
#    scale_y_continuous(expand = c(0,0), limits = c(0,2), breaks = seq(0,2,1)) +
#    theme_cowplot(12)  +
#   labs(y = "C1 n") +
#    theme_rem_xaxis +
#    theme(plot.margin = margin(7,0,-2,0))
# pl_C2_n <- ggplot() +
#    geom_vline(xintercept = seq(1950,2020,5), linetype = 'dashed', colour = 'grey60') +
#    geom_step(data = pl_freq_list$C2, aes(x = year, y = n)) +
#    scale_x_continuous(expand = c(0,0), limits = c(1950,2022), breaks = seq(1950,2020,10)) +
#    scale_y_continuous(expand = c(0,0), limits = c(0,2), breaks = seq(0,2,1), position = 'right') +
#    theme_cowplot(12)  +
#   labs(y = "C2 n")+
#    theme_rem_xaxis +
#    theme(plot.margin = margin(7,0,-2,0))
# pl_C3_n <- ggplot() +
#    geom_vline(xintercept = seq(1950,2020,5), linetype = 'dashed', colour = 'grey60') +
#    geom_step(data = pl_freq_list$C3, aes(x = year, y = n)) +
#    scale_x_continuous(expand = c(0,0), limits = c(1950,2022), breaks = seq(1950,2020,10)) +
#    scale_y_continuous(expand = c(0,0), limits = c(0,2), breaks = seq(0,2,1), position = 'left') +
#    theme_cowplot(12) +
#   labs(y = "C3 n")+
#    theme_rem_xaxis +
#    theme(plot.margin = margin(7,0,-2,0))
# pl_C4_n <- ggplot() +
#    geom_vline(xintercept = seq(1950,2020,5), linetype = 'dashed', colour = 'grey60') +
#    geom_step(data = pl_freq_list$C4, aes(x = year, y = n)) +
#    scale_x_continuous(expand = c(0,0), limits = c(1950,2022), breaks = seq(1950,2020,10)) +
#    scale_y_continuous(expand = c(0,0), limits = c(0,2), breaks = seq(0,2,1), position = 'right') +
#    theme_cowplot(12) +
#   labs(y = "C4 n")+
#    # theme_rem_xaxis +
#    theme(plot.margin = margin(7,0,7,0))
# 
# cowplot::plot_grid(pl_C1_n,
#                    pl_C2_n,
#                    pl_C3_n,
#                    pl_C4_n,
#                    nrow = 4, ncol = 1, align = 'v')
# 
# # Need stacked frequencies.
# empty_dat <- data.frame(year = seq(1950,2022,1),
#                         total_events = 0)
# pl_yearly_events <- PL_100mmRainfall_Trajectories %>%
#   mutate(year = year(date.start)) %>%
#   group_by(year) %>%
#   summarise(total_events = n()/73) %>%
#   full_join(empty_dat, by = 'year') %>%
#   mutate(total_events = ifelse(!is.na(total_events.x),
#                                total_events.x,
#                                total_events.y)) %>%
#   arrange(year) %>% dplyr::select(-c(total_events.x,total_events.y))
# sc_yearly_events <- SC_100mmRainfall_Trajectories %>%
#   mutate(year = year(date.start)) %>%
#   group_by(year) %>%
#   summarise(total_events = n()/73) %>%
#   full_join(empty_dat, by = 'year') %>%
#   mutate(total_events = ifelse(!is.na(total_events.x),
#                                total_events.x,
#                                total_events.y)) %>%
#   arrange(year) %>% dplyr::select(-c(total_events.x,total_events.y))
# 
# # Stacked events/year and rainfall/year
# 
# # Monthly
# PL_monthly_rainfall <- PLCombined_rainfall_data %>%
#   group_by(Month_seq) %>%
#   summarise(month_mm = sum(Rainfall.amount..millimetres., na.rm = T), Year = unique(Year), Month = unique(Month)) %>% ungroup() %>%
#   mutate(yr_month = paste0(Year,"-",str_pad(Month,2,side = "left","0"))) %>%
#   mutate(month_seq = seq(1,nrow(.),1))
# SC_monthly_rainfall <- SC_rainfall_data %>%
#   group_by(Month_seq) %>%
#   summarise(month_mm = sum(Rainfall.amount..millimetres., na.rm = T), Year = unique(Year), Month = unique(Month))
# #
# 
# PL_monthly_rainplot <- ggplot() +
#   geom_step(data = PL_annrain_stepfmt, aes(x = Year, y = ann_rain)) +
#   geom_line(data = PL_monthly_rainfall, aes(x = month_seq, y = month_mm)) +
#   scale_x_continuous(expand = c(0,0), limits = c(1950,2025), breaks = seq(1950,2020,10)) +
#   scale_y_continuous(expand = c(0,0), limits = c(800,2700), breaks = seq(1000,2500,500)) +
#   theme_cowplot(12)
# 
# PL_annual_rain <- PL_monthly_rainfall %>%
#   group_by(Year) %>%
#   summarise(ann_rain = sum(month_mm)) %>%
#   arrange(Year)
# 
# PL_annrain_stepfmt <- rbind(PL_annual_rain,PL_annual_rain[nrow(PL_annual_rain),])
# PL_annrain_stepfmt$Year[75] <- 2024
# 
# PL_annual_rainplot <- ggplot() +
#   geom_vline(xintercept = seq(1950,2020,10), linetype = 'dashed', colour = 'grey60') +
#   # geom_hline(yintercept = seq(1000,2500,500), linetype = 'dotted') +
#   geom_step(data = PL_annrain_stepfmt, aes(x = Year, y = ann_rain)) +
#   scale_x_continuous(expand = c(0,0), limits = c(1950,2025), breaks = seq(1950,2020,10)) +
#   scale_y_continuous(expand = c(0,0), limits = c(800,2700), breaks = seq(1000,2500,500)) +
#   labs(x = "Year", y = "Annual rainfall (mm)") +
#   theme_cowplot(12)



```

#### Broad patterns in rainfall

```{r rainfall-proportion-crunching, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 6, fig.width = 11, units = cm}
## Section notes
# Ok, so how do these vary in different phases?

## Parse based on the starting month.
# Make frame with SST phases
ENSO_months = nino_forplot %>%
  mutate(SST = ifelse(Over.5 == 1,
                        yes = "Positive",
                        no = ifelse(Under.5 == 1,
                                    yes = "Negative",
                                    no = "Neutral"))) %>%
  mutate(YYYY.MM = paste0(Year,"-",str_pad(Month,2,side = 'left', pad = "0")))

## Now match to the starting dates of the trajectories
PL_start_dates <- pl_4clus$data$traj %>%
  ungroup() %>%
  filter(hour.inc == -1) %>%
  dplyr::select(date,cluster) %>%
  mutate(YYYY.MM = format(as.Date(date, "%Y-%m-%d"), "%Y-%m")) %>%
  rename(PL.cluster = cluster) %>%
  dplyr::select(YYYY.MM, PL.cluster) %>%
  group_by(YYYY.MM,PL.cluster) %>%
  summarise(PL.n = n()) %>% ungroup()
SC_start_dates <- sc_4clus$data$traj %>%
  ungroup() %>%
  filter(hour.inc == -1) %>%
  dplyr::select(date,cluster) %>%
  mutate(YYYY.MM = format(as.Date(date, "%Y-%m-%d"), "%Y-%m"))  %>%
  rename(SC.cluster = cluster) %>%
  dplyr::select(YYYY.MM, SC.cluster) %>%
  group_by(YYYY.MM,SC.cluster) %>%
  summarise(SC.n = n()) %>% ungroup()

# Find ENSO phases using 5-month periods where the anomaly exceeds the 0.5 boundary (using 3-month smoothing)
# La Nina
out <- data.frame(unclass(rle(as.vector(nino_forplot$Under.5) == 1)))
out$pos <- head(cumsum(c(1, out$lengths)), -1)
LaNinaEps = out[out$lengths>=5  & out$values,c("pos", "lengths")]
# And now el nino
out <- data.frame(unclass(rle(as.vector(nino_forplot$Over.5) == 1)))
out$pos <- head(cumsum(c(1, out$lengths)), -1)
ElNinoEps = out[out$lengths>=5  & out$values,c("pos", "lengths")]
# Generate month sequences of phases
EN_sequence <- sequence(c(ElNinoEps$lengths), c(ElNinoEps$pos)) %>%
  as.data.frame() %>% 'colnames<-'(c('month_seq')) %>%
  mutate(ENSO_phase = 'El-Nino')
LN_sequence <- sequence(c(LaNinaEps$lengths), c(LaNinaEps$pos)) %>%
  as.data.frame() %>% 'colnames<-'(c('month_seq')) %>%
  mutate(ENSO_phase = 'La-Nina')
# Combine, sort, and join
join_frame <- data.frame(month_seq = seq(1,888,1))
ENSO_sequences <- rbind(EN_sequence,LN_sequence) %>%
  arrange(month_seq)
# Join, modify
ENSO_frame_full <- ENSO_sequences %>%
  full_join(join_frame) %>%
  arrange(month_seq) %>%
  mutate(ENSO_phase = ifelse(is.na(ENSO_phase),
                             yes = 'Neutral',
                             no = ENSO_phase))
# Join to create complete ENSO record
ENSO_frame <- ENSO_months %>%
  mutate(ENSO_phase = c(NA,ENSO_frame_full$ENSO_phase[2:887],NA))  %>%
  group_by(ENSO_phase) %>%
  mutate(ph_id = cur_group_id()) %>% ungroup() %>%
  mutate(phase_id2 = ph_id + cumsum(c(0, as.numeric(diff(ph_id)) != 0))) %>%
  group_by(ENSO_phase) %>%
  mutate(phase_id = cumsum(c(0, as.numeric(diff(phase_id2)) != 0)) + 1) %>% ungroup()


# Now bind with trajectory columns
# ENSO_frame_wclus <- ENSO_frame %>%
#   left_join(PL_start_dates, by = "YYYY.MM") %>%
#   left_join(SC_start_dates, by = "YYYY.MM")

# This is still struggling with cases where there are several events from different clusters in the same month.
PL_start_dates_wenso <- PL_start_dates %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>% 
  mutate(site = "PL") %>% rename(cluster = PL.cluster, n = PL.n)
SC_start_dates_wenso <- SC_start_dates %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>% 
  mutate(site = "SC") %>% rename(cluster = SC.cluster, n = SC.n)

start_dates_combined <- rbind(PL_start_dates_wenso,SC_start_dates_wenso)

# Now calculate proportions
# El Nino
ENSO_clusprops <- start_dates_combined %>%
  # filter(ENSO_phase == "El-Nino") %>% #rename(cluster = PL.cluster) %>%
  group_by(ENSO_phase, cluster, site) %>%
  summarise(n = sum(n)) %>% group_by(site, ENSO_phase) %>%
  mutate(freq = n/sum(n))

# El Nino, the long way; code here for posterity
PL_EN <- PL_start_dates_wenso %>%
  filter(ENSO_phase == "El-Nino") %>% #rename(cluster = PL.cluster) %>%
  group_by(cluster) %>%
  summarise(n = sum(n)) %>% ungroup() %>%
  mutate(freq = n/sum(n))
SC_EN <- SC_start_dates_wenso %>%
  filter(ENSO_phase == "El-Nino")  %>% #rename(cluster = SC.cluster) %>%
  group_by(cluster) %>%
  summarise(n = sum(n)) %>% ungroup() %>%
  mutate(freq = n/sum(n))

# Total sums between phases (i.e., how many events?)
ENSO_eventprops <- ENSO_clusprops %>%
  group_by(ENSO_phase, site) %>%
  summarise(n = sum(n)) %>% group_by(site) %>%
  mutate(freq = n/sum(n))

# Total rainfall between phases (100 mm events)
# This isn't useful; need the mean of total rainfall for each ENSO event.
rainfall_100mm_phase_sums <- PL_100mm %>%
  mutate(site = "PL") %>%
  bind_rows(., SC_100mm %>% mutate(site = "SC")) %>%
  mutate(YYYY.MM = format(as.Date(date_yyyymmdd, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(YYYY.MM, Rainfall.amount..millimetres., site) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase), by = "YYYY.MM") %>%
  group_by(ENSO_phase, site) %>%
  summarise(total_rainfall = sum(Rainfall.amount..millimetres.))

# Mean 100mm rainfall per ENSO phase 
rainfall_100mm_phase_sums <- PL_100mm %>%
  mutate(site = "PL") %>%
  bind_rows(., SC_100mm %>% mutate(site = "SC")) %>%
  mutate(YYYY.MM = format(as.Date(date_yyyymmdd, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(YYYY.MM, Rainfall.amount..millimetres., site) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>%
  group_by(ENSO_phase, site, phase_id) %>%
  summarise(phase_rainfall = sum(Rainfall.amount..millimetres.)) %>%
  group_by(ENSO_phase, site) %>%
  summarise(mean_rainfall_perphase = mean(phase_rainfall)) %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))

# As above, but normalised by phase duration
rainfall_100mm_phase_sums_norm <- PL_100mm %>%
  mutate(site = "PL") %>%
  bind_rows(., SC_100mm %>% mutate(site = "SC")) %>%
  mutate(YYYY.MM = format(as.Date(date_yyyymmdd, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(YYYY.MM, Rainfall.amount..millimetres., site) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>%
  group_by(ENSO_phase, site, phase_id) %>%
  summarise(phase_rainfall = sum(Rainfall.amount..millimetres.)/n()) %>%
  group_by(ENSO_phase, site) %>%
  summarise(mean_rainfall_perphase = mean(phase_rainfall)) %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))

# Total rainfall per phase event (all rainfall)
rainfall_all_event_sums <- PL_monthly_rainfall %>% 
  rename(YYYY.MM = yr_month) %>%
  mutate(site = "PL") %>%
  bind_rows(., SC_monthly_rainfall %>% mutate(site = "SC") %>% rename(YYYY.MM = yr_month)) %>%
  # mutate(YYYY.MM = format(as.Date(date_yyyymmdd, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(YYYY.MM, month_mm, site) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>%
  group_by(ENSO_phase, site, phase_id) %>%
  summarise(phase_rainfall = sum(month_mm)) %>%
  group_by(ENSO_phase, site) %>%
  summarise(mean_rainfall_perphase = mean(phase_rainfall)) %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))
# Total rainfall per phase event (all rainfall); EVENT DURATION NORMALISED (in months).
rainfall_all_event_sums_norm <- PL_monthly_rainfall %>% 
  rename(YYYY.MM = yr_month) %>%
  mutate(site = "PL") %>%
  bind_rows(., SC_monthly_rainfall %>% mutate(site = "SC") %>% rename(YYYY.MM = yr_month)) %>%
  # mutate(YYYY.MM = format(as.Date(date_yyyymmdd, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(YYYY.MM, month_mm, site) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>%
  group_by(ENSO_phase, site, phase_id) %>%
  summarise(norm_phase_rainfall = sum(month_mm)/n(), n = n()) %>%
  group_by(ENSO_phase, site) %>%
  summarise(mean_rainfall_perphase = mean(norm_phase_rainfall), n = n()) %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))
# 
# JT is also after the mean size of each event during the different phases. So, need to make a frequency-normalised mean.
# BUT this requires a two-day sum...
PL_rainfall_events_phases <- PL_100mm %>%
  mutate(YYYY.MM = paste0(Year,"-",str_pad(Month,2,side = "left","0"))) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>%
  group_by(ENSO_phase) %>%
  summarise(event_phase_rainfall = mean(event_rainfall), n = n()) %>%
  # group_by(ENSO_phase, site) %>%
  # summarise(mean_rainfall_perevent = mean(norm_event_rainfall), n = n()) %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))
SC_rainfall_events_phases <- SC_100mm %>%
  mutate(YYYY.MM = paste0(Year,"-",str_pad(Month,2,side = "left","0"))) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase, phase_id), by = "YYYY.MM") %>%
  group_by(ENSO_phase) %>%
  summarise(event_phase_rainfall = mean(event_rainfall), n = n()) %>%
  # group_by(ENSO_phase, site) %>%
  # summarise(mean_rainfall_perevent = mean(norm_event_rainfall), n = n()) %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))



```

Rainfall proportions during different ENSO phases 

```{r rainfall-phase-bars, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 9, fig.width = 12, units = cm}
## Section notes
# Some bars with rainfall

# Themes common to all
rain_bar_themes <- list(
  theme_tiff(textsize_vsmall/.pt),
  scale_fill_manual(values = c("red","grey","blue")),
  theme(plot.title = element_text(hjust = 0.5))
)

# Four figures:
# First, total mean rainfall during ENSO phases.
rainfall_hist <- ggplot() + 
  geom_bar(data = rainfall_all_event_sums %>% 
             filter(!is.na(ENSO_phase)) %>%
             mutate(site = factor(site, levels = c('SC','PL'))), 
                 aes(x = site, y = mean_rainfall_perphase, group = ENSO_phase, fill = ENSO_phase), stat = 'identity', position = 'dodge') +
  labs(x = "Site", y = "Mean rainfall (mm)", title = "Mean rainfall per ENSO phase") +
  rain_bar_themes +
  theme(legend.position = 'none')

# Next, total mean rainfall during ENSO phases, normalised by phase duration in months
rainfall_norm_hist  <- ggplot() + 
  geom_bar(data = rainfall_all_event_sums_norm %>% 
             filter(!is.na(ENSO_phase)) %>%
             mutate(site = factor(site, levels = c('SC','PL'))), 
                 aes(x = site, y = mean_rainfall_perphase, group = ENSO_phase, fill = ENSO_phase), stat = 'identity', position = 'dodge') +
  labs(x = "Site", y = "Mean rainfall (mm)", title = paste0("Mean rainfall per ENSO month","\n","(phase duration normalised)")) +
  rain_bar_themes +
  theme(legend.position = 'none')

# Next, total mean rainfall from >100 mm events during ENSO events.
largerainfall_hist  <- ggplot() + 
  geom_bar(data = rainfall_100mm_phase_sums %>% 
             filter(!is.na(ENSO_phase)) %>%
             mutate(site = factor(site, levels = c('SC','PL'))), 
                 aes(x = site, y = mean_rainfall_perphase, group = ENSO_phase, fill = ENSO_phase), stat = 'identity', position = 'dodge') +
  labs(x = "Site", y = "Mean rainfall (mm)", title = "Mean large event rainfall per ENSO phase") +
  rain_bar_themes +
  theme(legend.position = 'none')

# Finally, as above but normalised by phase duration in months.
largerainfall_norm_hist  <- ggplot() + 
  geom_bar(data = rainfall_100mm_phase_sums_norm %>% 
             filter(!is.na(ENSO_phase)) %>%
             mutate(site = factor(site, levels = c('SC','PL'))), 
                 aes(x = site, y = mean_rainfall_perphase, group = ENSO_phase, fill = ENSO_phase), stat = 'identity', position = 'dodge') +
  labs(x = "Site", y = "Mean rainfall (mm)", title = paste0("Mean large event rainfall per ENSO month","\n","(phase duration normalised)")) +
  rain_bar_themes +
  theme(legend.position = 'none')

# for seperate legend
largerainfall_norm_hist_leg  <- ggplot() + 
  geom_bar(data = rainfall_100mm_phase_sums_norm %>% 
             filter(!is.na(ENSO_phase)) %>%
             mutate(site = factor(site, levels = c('SC','PL'))), 
                 aes(x = site, y = mean_rainfall_perphase, group = ENSO_phase, fill = ENSO_phase), stat = 'identity', position = 'dodge') +
  labs(fill = "ENSO phase") +
  rain_bar_themes
legend_rainbars <- get_legend(
  # create some space to the left of the legend
  largerainfall_norm_hist_leg + theme(legend.box.margin = margin(-7, 0, 7, 12))
)

col1 <- plot_grid(NULL,
                   NULL, nrow = 2, ncol = 1)
col2 <- plot_grid(rainfall_hist,
                   largerainfall_hist,
                   nrow = 2, ncol = 1)
col4 <- plot_grid(rainfall_norm_hist,
                   largerainfall_norm_hist,
                   nrow = 2, ncol = 1)
col5 <- plot_grid(legend_rainbars,
                   NULL, nrow = 2, ncol = 1)
# cowplot::plot_grid(rainfall_hist, rainfall_norm_hist,
#                    largerainfall_hist, largerainfall_norm_hist,
#                    nrow = 2, ncol = 2)
col3 <- plot_grid(NULL,
                  NULL,
                  nrow = 2, ncol = 1)
## Tiff bits
hgt = 7
wd = 12
scaling = 1
tiff(paste0(tiff_dir,"Rainfall-phase-proportions.tiff"),
     units = "cm",
     width = wd * scaling, height = hgt * scaling,
     res = 300)
plot_grid(col1,col2,col3,col4,col5,
          nrow = 1, ncol = 5,
          rel_widths = c(0.1,1,0.2,1,0.3))
## Close null device for tiff export
while (!is.null(dev.list()))  dev.off()

```

Fig. Mean rainfall at each site during ENSO phases. Top row is using the mean of all rainfall that falls during a given ENSO phase, and the lower row is restricted to the rainfall contributed to by large events. The right column plots are normalised by event duration (i.e. the results are not biased by longer phases, which will often inevitably exhibit greater rainfall totals). 

#### Broad patterns in large event trajectory travel

Bulk groupings of cluster proportions for each site are displayed below, both in total (i.e. number of events) and as frequencies (i.e. percentages).

```{r cluster-freq-travel, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 6, fig.width = 11, units = cm}
## Section notes
# Ok, so how do these vary in different phases?

# Start with mean composiion of trajectories.

# Comparing ns
total_traj_data <- length(which(pl_4clus$data$traj$cluster == "C-W"))/73

# PL 
PL_composition <- pl_4clus$data$results %>%
  ungroup() %>%
  filter(hour.inc == 0) %>%
  dplyr::select(cluster,n,freq) %>%
  mutate(site = "PL") %>%
  mutate(n = n/73)
# SC
SC_composition <- sc_4clus$data$results %>%
  ungroup() %>%
  filter(hour.inc == 0) %>%
  dplyr::select(cluster,n,freq)  %>%
  mutate(site = "SC") %>%
  mutate(n = n/73)
# Both
bulk_comp <- rbind(SC_composition,
                   PL_composition) %>%
  mutate(site = factor(site, levels = c("SC","PL")))


freq_bar <- ggplot() + 
  geom_bar(data = bulk_comp, aes(x = site, y = freq, fill = cluster, group = cluster), position = 'stack', stat = 'identity') +
  scale_fill_manual(values = brewer.pal(n = 5, name = 'Set1')) +
    geom_text(data = bulk_comp, aes(x = site, y = freq, group = cluster, label = paste0(sprintf("%1.1f", freq),"%")),
              position = position_stack(vjust = 0.5), size = textsize_small/.pt/.pt) +
  theme_tiff(textsize_small/.pt) +
  labs(x = "Site", y = "Frequency", fill = "Cluster") +
  scale_y_continuous(expand = c(0,0)) + 
  theme(legend.position = 'none')

n_bar <- ggplot() + 
  geom_bar(data = bulk_comp, aes(x = site, y = n, fill = cluster, group = cluster), position = 'stack', stat = 'identity') +
  scale_fill_manual(values = brewer.pal(n = 5, name = 'Set1')) +
    geom_text(data = bulk_comp, aes(x = site, y = n, group = cluster, label = n),
              position = position_stack(vjust = 0.5), size = textsize_small/.pt/.pt) +
  theme_tiff(textsize_small/.pt) +
  labs(x = "Site", y = "Number of events", fill = "Cluster") +
  scale_y_continuous(expand = c(0,0))
## Tiff bits
hgt = 6
wd = 11
scaling = 1
tiff(paste0(tiff_dir,"Trajectory-travel-proportions.tiff"),
     units = "cm",
     width = wd * scaling, height = hgt * scaling,
     res = 300)
## ggplot code block
cowplot::plot_grid(freq_bar,n_bar,
                   nrow = 1, ncol = 2,
                   rel_widths = c(0.45,0.55))
## Close null device for tiff export
while (!is.null(dev.list()))  dev.off()
```

Fig. Proportions (frequencies) and quantities of large (>100 mm) rainfall events associated with trajectory clusters to Sandy Cape and Point Lookout, 1950-2022. Some similarities are immediately apparent - for instance, whilst Point Lookout received more large events during this period, both sites received an identical number of C-W events. Interestingly, none of these are on the same day! So, this 

#### ENSO phase effect on trajectory travel

Trajectory clusters were grouped by month (i.e., the same resolution as the Nino3.4 series and parsed into their respective ENSO phases. 

```{r cluster-freq-proportions, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.height = 12, fig.width = 14, units = cm}
## Section notes
# Ok, so how do these vary in different phases?

# Start with mean composiion of trajectories.

# Comparing ns
# total_traj_data <- length(which(pl_4clus$data$traj$cluster == "C-W"))/73

# Isolate and combine cluster arrival dates
PL_tab <- pl_4clus$data$traj %>%
  ungroup() %>%
  filter(hour.inc == -1) %>%
  mutate(site = "PL") %>%
  mutate(YYYY.MM = format(as.Date(date, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(cluster,YYYY.MM,site)
SC_tab <- sc_4clus$data$traj %>%
  ungroup() %>%
  filter(hour.inc == -1) %>%
  mutate(site = "SC") %>%
  mutate(YYYY.MM = format(as.Date(date, "%Y-%m-%d"), "%Y-%m")) %>%
  dplyr::select(cluster,YYYY.MM,site)
clus_tab <- rbind(PL_tab,SC_tab) %>%
  mutate(site = factor(site, levels = c("SC","PL"))) %>%
  left_join(ENSO_frame %>% dplyr::select(YYYY.MM, ENSO_phase), by = "YYYY.MM") %>%
  mutate(ENSO_phase = factor(ENSO_phase, levels = c("El-Nino","Neutral","La-Nina")))

## Now counts, by phase.
 # The freq here is the proportion of a cluster, within a phase, for a site. i.e. 'what % of events at SC, during El Nino, belong to C-E?'
clus_phase_counts <- clus_tab %>%
  group_by(ENSO_phase,site,cluster) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))

# First N, then freq
# Facet by site, x by phase, group + fill by cluster.


# Compositions: x = site, group = 
n_bar_enso <- ggplot() + 
  geom_bar(data = clus_phase_counts, aes(x = ENSO_phase, y = n, fill = cluster, group = cluster), position = 'stack', stat = 'identity') +
  facet_grid(~ site) +
  scale_fill_manual(values = brewer.pal(n = 5, name = 'Set1')) +
    geom_text(data = clus_phase_counts, aes(x = ENSO_phase, y = n, group = cluster, label = n),
              position = position_stack(vjust = 0.5), size = textsize_vsmall/.pt/.pt) +
  theme_tiff(textsize_vsmall/.pt) +
  labs(x = "ENSO phase", y = "Number of events", fill = "Cluster") +
  scale_y_continuous(expand = c(0,0), limits = c(0,70), breaks = seq(0,70,10))# +
  # theme(axis.text.x = element_blank())

freq_bar_enso <- ggplot() + 
  geom_bar(data = clus_phase_counts, aes(x = ENSO_phase, y = freq, fill = cluster, group = cluster), position = 'stack', stat = 'identity') +
  facet_grid(~ site) +
  scale_fill_manual(values = brewer.pal(n = 5, name = 'Set1')) +
    geom_text(data = clus_phase_counts, aes(x = ENSO_phase, y = freq, group = cluster, label = paste0(100 * round(freq,3),"%")),
              position = position_stack(vjust = 0.5), size = textsize_vsmall/.pt/.pt) +
  theme_tiff(textsize_vsmall/.pt) +
  labs(x = "ENSO Phase", y = "Frequency (%)", fill = "Cluster") +
  scale_y_continuous(expand = c(0,0))
# 
# n_bar <- ggplot() + 
#   geom_bar(data = bulk_comp, aes(x = site, y = n, fill = cluster, group = cluster), position = 'stack', stat = 'identity') +
#   scale_fill_manual(values = brewer.pal(n = 5, name = 'Set1')) +
#     geom_text(data = bulk_comp, aes(x = site, y = n, group = cluster, label = n),
#               position = position_stack(vjust = 0.5)) +
#   theme_cowplot(12) +
#   labs(x = "Site", y = "Number of events", fill = "Cluster") +
#   scale_y_continuous(expand = c(0,0))


## Tiff bits
hgt = 12
wd = 14
scaling = 1
tiff(paste0(tiff_dir,"Phase-cluster-proportion-bars.tiff"),
     units = "cm",
     width = wd * scaling, height = hgt * scaling,
     res = 300)
cowplot::plot_grid(n_bar_enso,freq_bar_enso,
                   nrow = 2, ncol = 1)
## Close null device for tiff export
while (!is.null(dev.list()))  dev.off()


```

Fig. Proportions (frequencies) and quantities of large (>100 mm) rainfall events associated with trajectory clusters to Sandy Cape and Point Lookout, 1950-2022. 

The only figure left that could be useful is large event rainfall quantity by phase! Would require some tweaking of code but could be done.